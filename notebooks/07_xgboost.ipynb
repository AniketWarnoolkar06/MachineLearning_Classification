{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34058c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f306b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best params: {'classifier__colsample_bytree': 0.9, 'classifier__learning_rate': 0.05, 'classifier__max_depth': 8, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 400, 'classifier__subsample': 0.9}\n",
      "Best CV F1: 0.3730968659897774\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_data import load_bank_data\n",
    "from src.data.preprocess import split_data, BankFeatureEngineer, build_enhanced_pipeline\n",
    "\n",
    "from src.models.xgboost_model import train_xgboost\n",
    "\n",
    "# Load dataset\n",
    "df = load_bank_data(\"../data/raw/bank-full.csv\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# Detect engineered columns\n",
    "fe = BankFeatureEngineer()\n",
    "X_tmp = fe.fit_transform(X_train)\n",
    "\n",
    "num_cols = X_tmp.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X_tmp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Build preprocessing pipeline\n",
    "preprocess_pipeline = build_enhanced_pipeline(num_cols, cat_cols)\n",
    "\n",
    "# Train XGB\n",
    "best_xgb, best_params, best_cv_f1 = train_xgboost(\n",
    "    preprocess_pipeline,\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best CV F1:\", best_cv_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b9a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.1979591836734694\n",
      "Best F1: 0.4958094397882664\n",
      "\n",
      "--- FINAL XGBOOST ---\n",
      "Accuracy: 0.8736038925135464\n",
      "AUC: 0.7971071704625757\n",
      "Precision: 0.46484698097601324\n",
      "Recall: 0.5311909262759924\n",
      "F1: 0.4958094397882664\n",
      "MCC: 0.4251538556403974\n"
     ]
    }
   ],
   "source": [
    "from src.models.xgboost_model import (\n",
    "    find_best_threshold,\n",
    "    evaluate_xgb,\n",
    "    save_xgboost,\n",
    ")\n",
    "\n",
    "# Find optimal threshold\n",
    "best_threshold, best_f1 = find_best_threshold(\n",
    "    best_xgb,\n",
    "    X_test,\n",
    "    y_test\n",
    ")\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(\"Best F1:\", best_f1)\n",
    "\n",
    "# Final evaluation\n",
    "metrics = evaluate_xgb(\n",
    "    best_xgb,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    best_threshold\n",
    ")\n",
    "\n",
    "print(\"\\n--- FINAL XGBOOST ---\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# Save model\n",
    "save_xgboost(best_xgb, best_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ML Assignment)",
   "language": "python",
   "name": "ml_assignment_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
